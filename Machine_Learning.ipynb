{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "## Sommaire\n",
    "-------------------\n",
    "\n",
    "### 1 - [Scikit-Learn](## Scikit-Learn)\n",
    "* #### _[Exercice 1](## Exercice 1)_\n",
    "\n",
    "### 2 - [Le framework](## Le framework)\n",
    "* #### _[Exercice 2](## Exercice 2)_\n",
    "\n",
    "### 3 - [Qualité des données](## Qualité des données)\n",
    "* #### _[Exercice 3](## Exercice 3)_\n",
    "* #### _[Exercice 4](## Exercice 2)_\n",
    "\n",
    "### 4 - [Cross Validation](## Cross Validation)\n",
    "* #### _[Exercice 5](## Exercice 5)_\n",
    "\n",
    "### 4 - [Evaluation](## Evaluation)\n",
    "* #### _[Exercice 6](## Exercice 6)_\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Scikit-Learn <a class=\"anchor\" id=\"Scikit-Learn\"></a>\n",
    "[`Sklearn`](http://scikit-learn.org/stable/) est la librairie de machine learning de Python. Elle regroupe des algorithmes de:\n",
    "\n",
    "* Classification\n",
    "* Regression\n",
    "* Clustering\n",
    "* Dimensionality reduction\n",
    "* Model selection\n",
    "* Preprocessing\n",
    "\n",
    "L'objectif d'un algorithm d'apprentissage supervisé est de créer une variable de sortie qui résume correctement le(s) variable(s) d'entrée(s). Pour créer cette variable, l'algorithme doit capturer les régularités dans les variables d'entrée mais aussi généraliser à des données non encore observées.\n",
    "\n",
    "L'objectif d'entrainement d'un algorithme est de trouver l'equilibre entre deux types d'erreurs qu'un model peut produire:\n",
    "* biais: la modélisation de la variable de sortie ne prend pas suffisament en compte les variations des variables d'entrée. On parle d'underfiting.\n",
    "* variance: le modèle prend trop en compte les variations des variables d'entrée. On parle d'overfiting.\n",
    "\n",
    "Pour équilibrer ces deux types d'erreurs, on utilise un échantillon d'entrainement et un échantillon de test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------------------\n",
    "\n",
    "### _ Exercice 1_ <a class=\"anchor\" id=\"Exercice 1\"></a>\n",
    "\n",
    "Utiliser le librairie `train_test_split()` sur les données carsdata pour générer un jeu d'entrainement de 75% et un jeu de test de 25% des données.\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Le framework <a class=\"anchor\" id=\"Le framework\"></a>\n",
    "L'algorithme est entrainé sur le training set, les prédictions se font sur le testing set et on évalue l'erreur du modèle.\n",
    "* fit\n",
    "* predict\n",
    "* evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------------------\n",
    "\n",
    "### _ Exercice 2_ <a class=\"anchor\" id=\"Exercice 2\"></a>\n",
    "\n",
    "* Entrainer une modèle de régression linéaire (`linear_model.LinearRegression()`)pour prédire la vitesse max à partir des données carsdata.\n",
    "* Prédir la vitesse max des données de test.\n",
    "* Evaluer la différence moyenne entre les prédictions et les valeurs réelles.\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Qualité des données <a class=\"anchor\" id=\"Qualité des données\"></a>\n",
    "\n",
    "La plupart des algorithmes de Machine Learning utilisent des données dans une matrice numpy stockées sous forme de `float`.\n",
    "La première étape de la mise en forme des données est d'identifier:\n",
    "* Les valeurs manquantes (NaN)\n",
    "* Les valeurs -Inf et +Inf\n",
    "* Les valeurs qui ne peuvent pas être castés en `float()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float('-1,0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([1.0,2.0,np.nan, np.inf]).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.,  20.],\n",
       "       [ nan,  inf]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X*10\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La bibliothèque sklearn dispose d'outils pour corriger facilement la qualité des données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp = Imputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette class va identifier les valeurs manquantes et les remplacer par la moyenne de l'axe. Ici l'axe est 0, donc les valeurs seront remplacées par la moyenne de la colone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.],\n",
       "       [ 10.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_inf = Imputer(missing_values=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values=inf, strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values=inf, strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_inf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20.],\n",
       "       [ 20.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_inf.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1], dtype=int64), array([1], dtype=int64))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isinf(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.,  20.],\n",
       "       [ nan,  inf]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1], dtype=int64), array([0], dtype=int64))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[np.where(np.isinf(X))] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.,  20.],\n",
       "       [ nan,  nan]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.,  20.],\n",
       "       [ 10.,  20.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = imp.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------------------\n",
    "\n",
    "### _ Exercice 3_ <a class=\"anchor\" id=\"Exercice 3\"></a>\n",
    "\n",
    "* A partir de `carsdata_features.csv`, créer une nouvelle DataFrame contenant les variables:\n",
    "`\"capacite_charge_max_kg\",\"empattement\",\"capacite_moteur_cc\",\"masse_admissible_max\",\n",
    "\"couple_max\",\"puissance_max_HP\"`\n",
    "\n",
    "* Vérifier et redresser la qualité des données\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les algorithmes de Machine Learning attendent des variable standardisées, c'est à dire de moyenne égale à 0 et une stadanrd deviation égale à 1. La raison principale est qu'une variable avec la variance la plus grande va dominer lors de l'entrainement. Le model predictif ne sera représentatif que de cette variable.\n",
    "\n",
    "Cette mise à l'echelle est gérée par un `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------------------\n",
    "\n",
    "### _ Exercice 4_ <a class=\"anchor\" id=\"Exercice 4\"></a>\n",
    "\n",
    "* Standardiser la DataFrame créée à l'Exercice 3\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Cross Validation <a class=\"anchor\" id=\"Cross Validation\"></a>\n",
    "\n",
    "Lors de l'entrainement d'un algorithme on veut s'assurer que les résultats des prédictions soient le plus représentatif possible des résultats qu'on obtiendra sur des données réelles. La clef est de répliquer de nombreuses fois l'entrainement et les tests puis d'aggréger les résultats des prédictions. Puisque ne nous n'avons pas accès à une quantité de données infinie, on utilise le hasard pour générer des échantillons d'entrainements différents.\n",
    "\n",
    "Cette boucle est gérée par `cross_validation.KFold`.\n",
    "`K` est le nombre de jeux d'entrainement différents qu'on veut générer à partir des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------------------\n",
    "\n",
    "### _ Exercice 5_ <a class=\"anchor\" id=\"Exercice 5\"></a>\n",
    "\n",
    "* Entrainer un algorithme de classification de votre choix pour prédire le type de voiture à partir de la DataFrame créée à l'Exercice 3.\n",
    "\n",
    "* Vous pouvez encoder les différents types de voitures de manière numérique pour créer la cible `y`\n",
    "\n",
    "```\n",
    "data[\"classe\"] = 0\n",
    "data.ix[data[\"bus\"]==1,\"classe\"] = 1 \n",
    "data.ix[data[\"cabriolet\"]==1,\"classe\"] = 2\n",
    "data.ix[data[\"coupe\"]==1,\"classe\"] = 3\n",
    "data.ix[data[\"hatchback\"]==1,\"classe\"] = 4\n",
    "data.ix[data[\"mpv\"]==1,\"classe\"] = 5\n",
    "data.ix[data[\"pickup\"]==1,\"classe\"] = 6\n",
    "data.ix[data[\"sedan\"]==1,\"classe\"] = 7\n",
    "data.ix[data[\"stationwagon\"]==1,\"classe\"] = 8\n",
    "data.ix[data[\"suv_crossover\"]==1,\"classe\"] = 9\n",
    "y = data.classe.as_matrix()\n",
    "```\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Evaluation <a class=\"anchor\" id=\"Evaluation\"></a>\n",
    "\n",
    "Les résultats de classifications multiclasses sont évalués par les mesures de precision et recall.\n",
    "\n",
    "\n",
    "\\\\[Precision = { tp \\over tp + fp } \\\\]\n",
    "\n",
    "\\\\[Recall = { tp \\over tp + fn } \\\\]\n",
    "\n",
    "En d'autres termes, la Precision mesure la quantité de faux positifs prédits dans une classe, et le Recall le nombre de faux negatifs manquants dans la prédiction d'une classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------------------\n",
    "\n",
    "### _ Exercice 6_ <a class=\"anchor\" id=\"Exercice 6\"></a>\n",
    "\n",
    "* Utiliser la librairie `sklearn.metrics.classification_report` pour générer les statistiques d'évaluation de la qualité des prédictions de l'Exercice 5.\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
